{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: torch in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: evaluate in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (2.17.1)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (4.38.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: click in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from transformers[torch]) (0.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: dill in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bianc\\desktop\\chatbot-nlp\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas nltk transformers[torch] torch matplotlib seaborn wordcloud scikit-learn evaluate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Chatbot-NLP\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import nltk # pip3 install nltk\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from LSTM import *\n",
    "from common import *\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET_NER = \"../../datasets/NER_dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[De, jeito, nenhum.], [ENTITY_PREFERENCE, ENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[Super-herói, de, ficção, científica], [ENTIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Eu, gosto], [ENTITY_PREFERENCE, ENTITY_PREFE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[Bem,, como, eu, disse, eu, eu, gosto, princi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[Sim,, absolutamente.], [ENTITY_PREFERENCE, E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         annotations\n",
       "0  [[De, jeito, nenhum.], [ENTITY_PREFERENCE, ENT...\n",
       "1  [[Super-herói, de, ficção, científica], [ENTIT...\n",
       "2  [[Eu, gosto], [ENTITY_PREFERENCE, ENTITY_PREFE...\n",
       "3  [[Bem,, como, eu, disse, eu, eu, gosto, princi...\n",
       "4  [[Sim,, absolutamente.], [ENTITY_PREFERENCE, E..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(PATH_DATASET_NER)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df = df[\"annotations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[Eu, gosto, de, filmes, de, aventura], [ENTIT...\n",
       "1    [[É, só, isso., Eu, não, sou, muito, fã, de, f...\n",
       "2    [[Foi, Houve, muitos, super-heróis, e, ação, n...\n",
       "Name: annotations, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(ner_df)\n",
    "ner_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 21, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = ner_df[:int(len(ner_df)*0.6)]\n",
    "df_test = ner_df[int(len(ner_df)*0.6):int(len(ner_df)*0.8)]\n",
    "df_val = ner_df[int(len(ner_df)*0.8):]\n",
    "\n",
    "len(df_train), len(df_test), len(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix, tag_to_ix = one_hot_encoding_mapper(ner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_DIM = 16\n",
    "OUTPUT_DIM = 5  # Número de tags de saída\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando LSTM no device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:06, 16.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 1.4662003857748849\n",
      "Epoch 2, Validation Loss: 1.3720722567467463\n",
      "Epoch 3, Validation Loss: 1.3007691417421614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:05, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Loss: 1.2449981910841805\n",
      "Epoch 5, Validation Loss: 1.2081712569509233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:00<00:05, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Loss: 1.1886645399388813\n",
      "Epoch 7, Validation Loss: 1.1799559451284862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:00<00:05, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Loss: 1.1800209865683602\n",
      "Epoch 9, Validation Loss: 1.1876442758809953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:00<00:04, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Loss: 1.1995617974372137\n",
      "Epoch 11, Validation Loss: 1.2193997168824786\n",
      "Epoch 12, Validation Loss: 1.2335938137202036\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:00<00:05, 16.75it/s]\n"
     ]
    }
   ],
   "source": [
    "model = train_lstm(NUM_EPOCHS, df_train, df_val, word_to_ix, tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61        42\n",
      "           1       0.62      0.70      0.66       113\n",
      "           2       0.61      0.60      0.60        75\n",
      "           4       0.29      0.31      0.30        16\n",
      "           5       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.60       256\n",
      "   macro avg       0.43      0.44      0.43       256\n",
      "weighted avg       0.58      0.60      0.58       256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Chatbot-NLP\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\bianc\\Desktop\\Chatbot-NLP\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\bianc\\Desktop\\Chatbot-NLP\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "test_LSTM(model, word_to_ix, tag_to_ix, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
