{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bianc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bianc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import random\n",
    "import nltk # pip3 install nltk\n",
    "from common import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from LSTM import *\n",
    "\n",
    "random.seed(42)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET = \"../../datasets/conversas_filmes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversa</th>\n",
       "      <th>Intenção</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quais são os filmes em cartaz?</td>\n",
       "      <td>Assistir filme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Onde posso comprar ingressos para os filmes de...</td>\n",
       "      <td>Comprar ingresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gostaria de saber mais sobre o filme \"Aventura...</td>\n",
       "      <td>Detalhes do filme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quando é a próxima sessão de \"Viagem Espacial\"?</td>\n",
       "      <td>Checar sessões</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qual é o melhor filme em exibição agora?</td>\n",
       "      <td>Assistir filme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Conversa           Intenção\n",
       "0                     Quais são os filmes em cartaz?     Assistir filme\n",
       "1  Onde posso comprar ingressos para os filmes de...   Comprar ingresso\n",
       "2  Gostaria de saber mais sobre o filme \"Aventura...  Detalhes do filme\n",
       "3    Quando é a próxima sessão de \"Viagem Espacial\"?     Checar sessões\n",
       "4           Qual é o melhor filme em exibição agora?     Assistir filme"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH_DATASET)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"Conversa\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df[\"Intenção\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Chatbot-NLP\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando LSTM no device cpu\n",
      "Epoch 1/25, Train Loss: 8.275959610939026, Val Loss: 1.384090542793274\n",
      "Epoch 2/25, Train Loss: 8.203581809997559, Val Loss: 1.3772534132003784\n",
      "Epoch 3/25, Train Loss: 8.083934783935547, Val Loss: 1.3608849048614502\n",
      "Epoch 4/25, Train Loss: 7.833807826042175, Val Loss: 1.3201602697372437\n",
      "Epoch 5/25, Train Loss: 7.320424675941467, Val Loss: 1.2347290515899658\n",
      "Epoch 6/25, Train Loss: 6.479583501815796, Val Loss: 1.0890238285064697\n",
      "Epoch 7/25, Train Loss: 5.324925243854523, Val Loss: 0.8911461234092712\n",
      "Epoch 8/25, Train Loss: 3.9412679076194763, Val Loss: 0.6963797211647034\n",
      "Epoch 9/25, Train Loss: 2.7132420241832733, Val Loss: 0.5604107975959778\n",
      "Epoch 10/25, Train Loss: 1.965013563632965, Val Loss: 0.48446890711784363\n",
      "Epoch 11/25, Train Loss: 1.517047181725502, Val Loss: 0.43152347207069397\n",
      "Epoch 12/25, Train Loss: 1.2003501504659653, Val Loss: 0.3833243250846863\n",
      "Epoch 13/25, Train Loss: 0.951064221560955, Val Loss: 0.33407294750213623\n",
      "Epoch 14/25, Train Loss: 0.7336851581931114, Val Loss: 0.2852182686328888\n",
      "Epoch 15/25, Train Loss: 0.532553918659687, Val Loss: 0.23959754407405853\n",
      "Epoch 16/25, Train Loss: 0.35442792251706123, Val Loss: 0.20258377492427826\n",
      "Epoch 17/25, Train Loss: 0.21789849549531937, Val Loss: 0.1779995560646057\n",
      "Epoch 18/25, Train Loss: 0.12995026260614395, Val Loss: 0.16464415192604065\n",
      "Epoch 19/25, Train Loss: 0.08048725314438343, Val Loss: 0.15834376215934753\n",
      "Epoch 20/25, Train Loss: 0.05415922915562987, Val Loss: 0.15543252229690552\n",
      "Epoch 21/25, Train Loss: 0.039773911237716675, Val Loss: 0.153892382979393\n",
      "Epoch 22/25, Train Loss: 0.03130478085950017, Val Loss: 0.15289050340652466\n",
      "Epoch 23/25, Train Loss: 0.025870929704979062, Val Loss: 0.15215663611888885\n",
      "Epoch 24/25, Train Loss: 0.022109919460490346, Val Loss: 0.1516246795654297\n",
      "Epoch 25/25, Train Loss: 0.019345249282196164, Val Loss: 0.15128208696842194\n"
     ]
    }
   ],
   "source": [
    "model = train_lstm(X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, len(df[\"Intenção\"].unique()), num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        62\n",
      "   macro avg       1.00      1.00      1.00        62\n",
      "weighted avg       1.00      1.00      1.00        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_LSTM(model, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
