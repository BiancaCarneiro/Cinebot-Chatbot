{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bianc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bianc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import random\n",
    "import nltk # pip3 install nltk\n",
    "from common import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from LSTM import *\n",
    "\n",
    "random.seed(42)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET = \"../../datasets/conversas_filmes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversa</th>\n",
       "      <th>Intenção</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quais são os filmes em cartaz?</td>\n",
       "      <td>Assistir filme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Onde posso comprar ingressos para os filmes de...</td>\n",
       "      <td>Comprar ingresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gostaria de saber mais sobre o filme \"Aventura...</td>\n",
       "      <td>Detalhes do filme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quando é a próxima sessão de \"Viagem Espacial\"?</td>\n",
       "      <td>Checar sessões</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qual é o melhor filme em exibição agora?</td>\n",
       "      <td>Assistir filme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Conversa           Intenção\n",
       "0                     Quais são os filmes em cartaz?     Assistir filme\n",
       "1  Onde posso comprar ingressos para os filmes de...   Comprar ingresso\n",
       "2  Gostaria de saber mais sobre o filme \"Aventura...  Detalhes do filme\n",
       "3    Quando é a próxima sessão de \"Viagem Espacial\"?     Checar sessões\n",
       "4           Qual é o melhor filme em exibição agora?     Assistir filme"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH_DATASET)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"Conversa\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df[\"Intenção\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Chatbot-NLP\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando LSTM no device cpu\n",
      "Epoch 1/100, Train Loss: 8.26051676273346, Val Loss: 1.3802459239959717\n",
      "Epoch 2/100, Train Loss: 8.188084483146667, Val Loss: 1.3728948831558228\n",
      "Epoch 3/100, Train Loss: 8.060454249382019, Val Loss: 1.3539717197418213\n",
      "Epoch 4/100, Train Loss: 7.7806466817855835, Val Loss: 1.30634605884552\n",
      "Epoch 5/100, Train Loss: 7.19752311706543, Val Loss: 1.2100114822387695\n",
      "Epoch 6/100, Train Loss: 6.274123013019562, Val Loss: 1.0579783916473389\n",
      "Epoch 7/100, Train Loss: 5.099261581897736, Val Loss: 0.8633590340614319\n",
      "Epoch 8/100, Train Loss: 3.7737021446228027, Val Loss: 0.6837930083274841\n",
      "Epoch 9/100, Train Loss: 2.667601704597473, Val Loss: 0.5640522837638855\n",
      "Epoch 10/100, Train Loss: 2.0253032743930817, Val Loss: 0.4915187358856201\n",
      "Epoch 11/100, Train Loss: 1.6234364360570908, Val Loss: 0.42785510420799255\n",
      "Epoch 12/100, Train Loss: 1.2847337424755096, Val Loss: 0.3602694869041443\n",
      "Epoch 13/100, Train Loss: 0.9740703999996185, Val Loss: 0.2921636402606964\n",
      "Epoch 14/100, Train Loss: 0.6882600039243698, Val Loss: 0.2275218516588211\n",
      "Epoch 15/100, Train Loss: 0.42961831763386726, Val Loss: 0.1742742359638214\n",
      "Epoch 16/100, Train Loss: 0.23624427244067192, Val Loss: 0.14114823937416077\n",
      "Epoch 17/100, Train Loss: 0.12499558366835117, Val Loss: 0.12561985850334167\n",
      "Epoch 18/100, Train Loss: 0.07167559862136841, Val Loss: 0.11921011656522751\n",
      "Epoch 19/100, Train Loss: 0.04685996240004897, Val Loss: 0.11600132286548615\n",
      "Epoch 20/100, Train Loss: 0.03423450654372573, Val Loss: 0.11371346563100815\n",
      "Epoch 21/100, Train Loss: 0.027001825626939535, Val Loss: 0.11182497441768646\n",
      "Epoch 22/100, Train Loss: 0.022419672226533294, Val Loss: 0.11033067852258682\n",
      "Epoch 23/100, Train Loss: 0.01927887531928718, Val Loss: 0.10928420722484589\n",
      "Epoch 24/100, Train Loss: 0.016985608730465174, Val Loss: 0.10868971049785614\n",
      "Epoch 25/100, Train Loss: 0.015222608810290694, Val Loss: 0.10850300639867783\n",
      "Epoch 26/100, Train Loss: 0.013810046948492527, Val Loss: 0.10865476727485657\n",
      "Epoch 27/100, Train Loss: 0.012641329667530954, Val Loss: 0.1090700775384903\n",
      "Epoch 28/100, Train Loss: 0.011650594882667065, Val Loss: 0.10968003422021866\n",
      "Early stopping! No improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "model = train_lstm(X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, len(df[\"Intenção\"].unique()), num_epochs=100, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        62\n",
      "   macro avg       1.00      1.00      1.00        62\n",
      "weighted avg       1.00      1.00      1.00        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_LSTM(model, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
